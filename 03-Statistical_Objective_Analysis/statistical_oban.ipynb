{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c27f76",
      "metadata": {
        "id": "55c27f76"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Created By    : Jared W. Marquis\n",
        "Creation Date : 01 August 2022\n",
        "Course        : ATSC 528 - Atmospheric Data Analysis\n",
        "Assignment    : #03 - Statistical Objective Analysis\n",
        "\n",
        "Purpose:\n",
        "Script to take sparse upper air observations and analyze them on a\n",
        "polar stereographic map projection using statistical objective analysis.\n",
        "[PUT MORE INFORMATION HERE - I.E., WHAT SPECIFIC THING IS BEING DONE]\n",
        "\n",
        "\"\"\"\n",
        "__author__    = \"Jared W. Marquis\"\n",
        "__contact__   = \"jared.marquis@und.edu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c022d753-7412-47a2-8a6d-3544951717b2",
        "outputId": "2385e6d4-579f-4ba1-d4c4-afb4cb8c0bd4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.8.0)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.6)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (24.1)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.3.1->cartopy) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#Used Colab for further works, supports Pip\n",
        "!pip install cartopy"
      ],
      "id": "c022d753-7412-47a2-8a6d-3544951717b2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7335135f",
      "metadata": {
        "id": "7335135f"
      },
      "outputs": [],
      "source": [
        "### Import Required Modules (shouldn't need to change) ###\n",
        "import numpy as np                 #numpy for math\n",
        "import matplotlib.pyplot as plt    #matplotlib for plotting\n",
        "import cartopy.crs as ccrs         #cartopy for plotting on map\n",
        "import cartopy.feature as cfeature #cartopy basic shapefiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e55bf048"
      },
      "outputs": [],
      "source": [
        "### Read in observations ###\n",
        "data_path = '/content/RAOBs_201903131200.txt'\n",
        "data = np.genfromtxt(data_path, delimiter=',', dtype=str)\n",
        "\n",
        "# Individual columns for each data\n",
        "station_ids = data[:, 0]  # Station IDs\n",
        "station_lat = data[:, 1].astype(float)  # Latitude values\n",
        "station_lon = data[:, 2].astype(float)  # Longitude values\n",
        "heights = data[:, 3].astype(float)  # 500-mb Height\n"
      ],
      "id": "e55bf048"
    },
    {
      "cell_type": "code",
      "source": [
        "phi0 = np.radians(60)  # central latitude φ0 in radians\n",
        "lambda0 = np.radians(-115)\n",
        "lat_rad=np.radians (station_lat)\n",
        "lon_rad=np.radians(station_lon) # central longitude λ0 in radians\n",
        "R = 6371*1000  # Earth's radius in meters\n",
        "m = 1 / 15000000  # map scale\n",
        "\n",
        "proj= ccrs.Stereographic(central_latitude=90, central_longitude=-115,true_scale_latitude=60)"
      ],
      "metadata": {
        "id": "wCevVrR6kUQ1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "wCevVrR6kUQ1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9464917a"
      },
      "outputs": [],
      "source": [
        "### Set up analysis map with a 22x28 rectangular grid of points ###\n",
        "x0, y0 = 18.90, -6.30\n",
        "dx, dy = 1.27, 1.27\n",
        "nx, ny = 22,28\n",
        "# Making a (22x28) grid\n",
        "x_grid = np.linspace(x0, x0 + (nx - 1) * dx, nx)\n",
        "y_grid = np.linspace(y0, y0 + (ny - 1) * dy, ny)\n",
        "\n",
        "X, Y = np.meshgrid(x_grid, y_grid)\n",
        "print(\"Shape of x_grid:\", x_grid.shape)\n",
        "print(\"Shape of y_grid:\", y_grid.shape)\n",
        "plt.scatter(X, Y, color='blue', label='Grid Points', marker='.')"
      ],
      "id": "9464917a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64629e3a"
      },
      "outputs": [],
      "source": [
        "# Function to convert latitude and longitude to x, y in stereographic projection\n",
        "def latlon_to_xy(station_lat, station_lon):\n",
        "\n",
        "  lat_rad = np.radians(station_lat)\n",
        "  lon_rad = np.radians(station_lon)\n",
        "\n",
        "  sigma = (1+np.sin(phi0)) / (1+np.sin(lat_rad))\n",
        "\n",
        "  x_obs = R * sigma * m *np.cos(lat_rad)*np.cos(np.radians(station_lon)-lambda0)*100\n",
        "\n",
        "  y_obs = R * sigma * m *np.cos(lat_rad)*np.sin(np.radians(station_lon)-lambda0)*100\n",
        "\n",
        "\n",
        "\n",
        "  return x_obs, y_obs\n",
        "\n",
        "# Apply the function to all latitude and longitude values\n",
        "obs_coords = np.array([latlon_to_xy(lat, lon) for lat, lon in zip(station_lat, station_lon)])\n",
        "\n",
        "# Separate x and y coordinates\n",
        "xk, yk = obs_coords[:, 0], obs_coords[:, 1]\n",
        "# Check the shape of obs_coords\n",
        "print(f\"obs_coords shape: {obs_coords.shape}\")\n",
        "\n",
        "#Plot the Stations and the Grid to Verify Alignment (I got wrong here somewhere)\n",
        "plt.scatter(X, Y, color='blue', label='Grid Points', marker='.')  # Plot the grid points\n",
        "plt.scatter(xk, yk, color='green', label='Converted Station Positions', marker='o')  # Plot station positions"
      ],
      "id": "64629e3a"
    },
    {
      "cell_type": "code",
      "source": [
        "r_e=12.7775892;\n",
        "Kd=10.8844524"
      ],
      "metadata": {
        "id": "BVfJrVH_v-ko"
      },
      "id": "BVfJrVH_v-ko",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = 1.24  # Range factor (Schlatter)\n",
        "b_prime = b * m**2  # Adjusted range factor for the grid\n",
        "\n",
        "# Schlatter correlation model\n",
        "def schlatter_correlation(s_squared, b_prime):\n",
        "    # s_squared is the squared distance\n",
        "    if s_squared == 0:\n",
        "        return 1.0  # Catch the case where s = 0 to ensure ρ(0) = 1\n",
        "    return 0.95 * np.exp(-b_prime * s_squared)"
      ],
      "metadata": {
        "id": "ms4HECCpy-L0"
      },
      "id": "ms4HECCpy-L0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_correlation_matrix(obs_coords, grid_coords, b_prime):\n",
        "    # Compute distances between observation points (ρ_kl)\n",
        "    distances_kl_squared = np.sum((obs_coords[:, None, :] - obs_coords[None, :, :])**2, axis=2)\n",
        "    rho_kl = np.vectorize(schlatter_correlation)(distances_kl_squared, b_prime)\n",
        "\n",
        "    # Compute distances between grid points and observation points (ρ_ki)\n",
        "    distances_ki_squared = np.sum((grid_coords[:, None, :] - obs_coords[None, :, :])**2, axis=2)\n",
        "    rho_ki = np.vectorize(schlatter_correlation)(distances_ki_squared, b_prime)\n",
        "\n",
        "    return rho_kl, rho_ki"
      ],
      "metadata": {
        "id": "IKRTpCMEzFA6"
      },
      "id": "IKRTpCMEzFA6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = []\n",
        "for grid_x, grid_y in zip(X.ravel(), Y.ravel()):\n",
        "    # Compute distance between grid point and observation points\n",
        "    distances_ki = np.sqrt((xk - grid_x)**2 + (yk - grid_y)**2)\n",
        "    rho_ki = correlation_function(distances_ki**2, Kd)\n",
        "\n",
        "    # Solve for weights: w_i = ρ^-1 * ρ_ki\n",
        "    w_i = np.linalg.solve(rho_kl, rho_ki)\n",
        "    weights.append(w_i)"
      ],
      "metadata": {
        "id": "le7J288j0F5b"
      },
      "id": "le7J288j0F5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_coords = np.column_stack((X.ravel(), Y.ravel()))\n",
        "rho_kl, rho_ki = calculate_correlation_matrix(obs_coords, grid_coords, b_prime)\n",
        "\n",
        "# Precompute the inverse of the correlation matrix ρ_kl\n",
        "rho_kl_inv = np.linalg.inv(rho_kl)\n",
        "\n",
        "# Compute weights for all grid points\n",
        "weights = rho_kl_inv @ rho_ki.T  # Matrix multiplication for all grid points\n",
        "\n",
        "# Reshape weights for visualization\n",
        "weights_grid = weights.T.reshape(X.shape + (len(xk),))  # Shape: (nx, ny, 135)\n",
        "\n",
        "# Display one set of weights for a single grid point\n",
        "weights_grid[0, 0]"
      ],
      "metadata": {
        "id": "TfP8uwWrz28r"
      },
      "id": "TfP8uwWrz28r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the grid\n",
        "grid_points = np.column_stack((x_grid.ravel(), y_grid.ravel()))\n",
        "background_field = np.zeros(grid_points.shape[0])\n",
        "\n",
        "for i, grid_point in enumerate(grid_points):\n",
        "    # Compute distances to all observation points\n",
        "    distances = cdist([grid_point], np.column_stack((obs_x, obs_y))).flatten()\n",
        "\n",
        "    # Consider only observations within the radius of influence\n",
        "    within_radius = distances < r_e\n",
        "    weights = weights[within_radius]\n",
        "    values = obs_height[within_radius]\n",
        "\n",
        "    if weights.size > 0:\n",
        "        background_field[i] = np.sum(weights * values) / np.sum(weights)\n",
        "    else:\n",
        "        background_field[i] = np.nan  # Mark as NaN if no points within radius\n",
        "\n",
        "# Reshape the background field to grid shape\n",
        "background_field = background_field.reshape(grid_shape)\n"
      ],
      "metadata": {
        "id": "FSOG-15zwIIf"
      },
      "id": "FSOG-15zwIIf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute analysis field for N closest stations\n",
        "def compute_analysis_field(N, X, Y, xk, yk, f_O, f_B_obs, f_B_grid):\n",
        "    f_A_grid = np.zeros(X.shape)  # Initialize analysis field\n",
        "\n",
        "    for i in range(X.shape[0]):\n",
        "        for j in range(X.shape[1]):\n",
        "            # Get the current grid point\n",
        "            grid_x, grid_y = X[i, j], Y[i, j]\n",
        "\n",
        "            # Compute distances from grid point to observation points\n",
        "            distances = np.sqrt((xk - grid_x)**2 + (yk - grid_y)**2)\n",
        "\n",
        "            # Get the indices of the N closest stations\n",
        "            closest_indices = np.argsort(distances)[:N]\n",
        "\n",
        "            # Extract weights, observation values, and background values for the closest stations\n",
        "            rho_kl_inv_closest = np.linalg.inv(rho_kl[np.ix_(closest_indices, closest_indices)])\n",
        "            rho_ki_closest = correlation_function(distances[closest_indices]**2, b_prime)\n",
        "            weights_closest = rho_kl_inv_closest @ rho_ki_closest\n",
        "\n",
        "            f_O_closest = f_O[closest_indices]\n",
        "            f_B_obs_closest = f_B_obs[closest_indices]\n",
        "\n",
        "            # Compute the analysis value\n",
        "            f_A_grid[i, j] = f_B_grid[i, j] + np.sum(\n",
        "                weights_closest * (f_O_closest - f_B_obs_closest)\n",
        "            )\n",
        "\n",
        "    return f_A_grid"
      ],
      "metadata": {
        "id": "ihJoz3SD1QdI"
      },
      "id": "ihJoz3SD1QdI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_A_grid_N2 = compute_analysis_field(2, X, Y, xk, yk, f_O, f_B_obs, f_B_grid)\n",
        "f_A_grid_N4 = compute_analysis_field(4, X, Y, xk, yk, f_O, f_B_obs, f_B_grid)\n",
        "f_A_grid_N10 = compute_analysis_field(10, X, Y, xk, yk, f_O, f_B_obs, f_B_grid)"
      ],
      "metadata": {
        "id": "Ip2j8D-X1U3k"
      },
      "id": "Ip2j8D-X1U3k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZbpKKSSYXWO"
      },
      "outputs": [],
      "source": [
        "X_meters = X * 0.01 # Convert cm to meters\n",
        "\n",
        "Y_meters = Y * 0.01 # Convert cm to meters\n",
        "\n",
        "\n",
        "\n",
        "# grid x-y coordinates back to latitude and longitude\n",
        "\n",
        "x_squared_y_squared = (X_meters/m)**2 + (Y_meters/m)**2\n",
        "\n",
        "lambda_grid = lambda0 + np.arctan(Y_meters/X_meters)\n",
        "\n",
        "phi_grid = (np.pi/2) - 2*np.arctan((x_squared_y_squared**0.5)/(R*(1+np.sin(phi0))))\n",
        "\n",
        "\n",
        "\n",
        "# Convert to degrees\n",
        "\n",
        "latitude_grid = np.degrees(phi_grid)\n",
        "\n",
        "longitude_grid = np.degrees(lambda_grid)"
      ],
      "id": "tZbpKKSSYXWO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Tvg7CLTYe1m",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Plot 500mb analyses over a map ###\n",
        "#convert x,y to lat/long\n",
        "\n",
        "LAT = latitude_grid\n",
        "LON = longitude_grid\n",
        "\n",
        "ROI = [R1,R2,R3]\n",
        "\n",
        "ANALYSIS=[Analysis1,Analysis2,Analysis3]\n",
        "\n",
        "proj = ccrs.Stereographic(central_longitude=-115,central_latitude=90,true_scale_latitude=60)\n",
        "fig = plt.figure(figsize=(5,15),dpi=200)\n",
        "for i in range(len(ROI)):\n",
        "    ax1 = fig.add_subplot(3,1,i+1,projection=proj)\n",
        "    ax1.add_feature(cfeature.STATES)\n",
        "    ax1.add_feature(cfeature.COASTLINE)\n",
        "    cs1 = ax1.contour(LON,LAT,ANALYSIS[i],colors='k',levels=np.arange(0,8000,60),transform=ccrs.PlateCarree())\n",
        "    plt.clabel(cs1,levels=np.arange(0,8000,60))\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "id": "_Tvg7CLTYe1m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZteT5f3YOTv"
      },
      "outputs": [],
      "source": [
        "def compute_rms_error(xk, yk, observations, analysis_grid, X, Y,RoI):\n",
        "\n",
        "    grid_points = np.column_stack((X.flatten(), Y.flatten()))\n",
        "    grid_values = analysis_grid.flatten()\n",
        "\n",
        "    # Interpolate analysis values at observation points\n",
        "    interpolated_analysis=bilinear_interpolation(xk, yk, X, Y, analysis_grid, RoI)\n",
        "\n",
        "\n",
        "    # Calculate the squared differences\n",
        "    differences = observations - interpolated_analysis\n",
        "    squared_differences = differences ** 2\n",
        "\n",
        "    # Compute RMS error\n",
        "    rms_error = np.sqrt(np.nanmean(squared_differences))  # nanmean ignores any NaN values\n",
        "    return rms_error\n",
        "rmse1 = compute_rms_error(xk, yk, heights, Analysis1, X, Y,R1)\n",
        "print(\"RMSE_1:\", rmse1)\n",
        "rmse2 = compute_rms_error(xk, yk, heights, Analysis2, X, Y,R2)\n",
        "print(\"RMSE_2:\", rmse2)\n",
        "rmse3 = compute_rms_error(xk, yk, heights, Analysis3, X, Y,R3)\n",
        "print(\"RMSE_3:\", rmse3)\n"
      ],
      "id": "AZteT5f3YOTv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNAAE8ngYkEx"
      },
      "outputs": [],
      "source": [
        "### Store the number of observations available for each grid point in text files ###\n",
        "np.savetxt(\"Analysis_first_pass.txt\", Analysis1, fmt=\"%.6f\", header=\"Analysis Heights for First Pass\")\n",
        "np.savetxt(\"Analysis_second_pass.txt\", Analysis2, fmt=\"%.6f\", header=\"Analysis Heights for Second Pass\")\n",
        "np.savetxt(\"Analysis_third_pass.txt\", Analysis3, fmt=\"%.6f\", header=\"Analysis Heights for Third Pass\")\n",
        "\n",
        "np.savetxt(\"Diff_2_1.txt\", Analysis1, fmt=\"%.6f\", header=\"Analysis2-Analysis1\")\n",
        "np.savetxt(\"Diff_3_1.txt\", Analysis2, fmt=\"%.6f\", header=\"Analysis3-Analysis1\")\n",
        "np.savetxt(\"Diff_3_2.txt\", Analysis3, fmt=\"%.6f\", header=\"Analysis3-Analysis2\")"
      ],
      "id": "cNAAE8ngYkEx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "661c6680",
      "metadata": {
        "id": "661c6680"
      },
      "outputs": [],
      "source": [
        "### In a separte text file (or below), answer the following questions ###\n",
        "'''\n",
        "1 - Describe the general features that you see in your contoured analyses.\n",
        "\n",
        "\n",
        "2 - Describe the differences that you see in your contoured analyses.\n",
        "    Does one analysis seem to be smoother than the other?  If so, what would cause this?\n",
        "\n",
        "\n",
        "3 - What happens as you increase the number of points considered for the analysis?  Is this\n",
        "    desirable?  Why or why not?\n",
        "\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}